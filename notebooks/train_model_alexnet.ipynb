{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ye2e7uOWEhI"
      },
      "source": [
        "# Training Model with Representation Tracking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U-fumgcWHdw",
        "outputId": "d0b7130d-feab-45b9-ed68-dcc4cb04eeaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"drive/MyDrive/CS159/\""
      ],
      "metadata": {
        "id": "Pt7zDIDLWREz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hjNzfdVUWEhL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import shape as s\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5csdUWFHW7tT",
        "outputId": "f0d050d8-1b71-4139-8350-4986efd2852d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay0oV66SXFLh",
        "outputId": "bb05c640-6160-4c59-b9a0-03b6d6c13819"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ticotj0oWEhM"
      },
      "outputs": [],
      "source": [
        "# Define parameters of some images\n",
        "DIM = 227"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cTlccGuRWEhO"
      },
      "outputs": [],
      "source": [
        "class AlexNet(Sequential):\n",
        "    '''\n",
        "    Here is an implementation of AlexNet in Tensorflow.\n",
        "    I have a lot of experience with AlexNet and it works pretty\n",
        "    well for most things. We can train from scratch or we can get the \n",
        "    pretrained ImageNet weights from the Internet and do stuff with it\n",
        "\n",
        "    We can also use networks ike VGG16 and ResNet (I think ResNet is classification)\n",
        "    and do similar things, we can just get those implemnetations there. \n",
        "    '''\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(11, 11), strides=4,\n",
        "                        padding='valid', activation='relu',\n",
        "                        input_shape=input_shape,\n",
        "                        kernel_initializer='he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
        "                              padding='valid', data_format=None))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(5, 5), strides=1,\n",
        "                        padding='same', activation='relu',\n",
        "                        kernel_initializer='he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
        "                              padding='valid', data_format=None))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3, 3), strides=1,\n",
        "                        padding='same', activation='relu',\n",
        "                        kernel_initializer='he_normal'))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3, 3), strides=1,\n",
        "                        padding='same', activation='relu',\n",
        "                        kernel_initializer='he_normal'))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(3, 3), strides=1,\n",
        "                        padding='same', activation='relu',\n",
        "                        kernel_initializer='he_normal'))\n",
        "\n",
        "        self.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
        "                              padding='valid', data_format=None))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(4096, activation='relu'))\n",
        "        self.add(Dropout(0.5))\n",
        "        self.add(Dense(4096, activation='relu'))\n",
        "        self.add(Dropout(0.5))\n",
        "        self.add(Dense(num_classes, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gDGHgdoMWEhQ"
      },
      "outputs": [],
      "source": [
        "class AlexNet_Input_to_Kernels(Sequential):\n",
        "    '''\n",
        "    H\n",
        "    '''\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(11, 11), strides=4,\n",
        "                        padding='valid', activation='relu',\n",
        "                        input_shape=input_shape,\n",
        "                        kernel_initializer='he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
        "                              padding='valid', data_format=None))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(5, 5), strides=1,\n",
        "                        padding='same', activation='relu',\n",
        "                        kernel_initializer='he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
        "                              padding='valid', data_format=None))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3, 3), strides=1,\n",
        "                        padding='same', activation='relu',\n",
        "                        kernel_initializer='he_normal'))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3, 3), strides=1,\n",
        "                        padding='same', activation='relu',\n",
        "                        kernel_initializer='he_normal'))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(3, 3), strides=1,\n",
        "                        padding='same', activation='relu',\n",
        "                        kernel_initializer='he_normal'))\n",
        "\n",
        "        self.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
        "                              padding='valid', data_format=None))\n",
        "        self.add(Flatten(input_shape=(6, 6, 256)))\n",
        "        # self.add(Dense(4096, activation='relu'))\n",
        "#         self.add(Dropout(0.5))\n",
        "#         self.add(Dense(4096, activation= 'relu'))\n",
        "#         self.add(Dropout(0.5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1llNnupWEhS",
        "outputId": "8754a3ed-21e8-4da9-e589-5d20cfc0a9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 567 files belonging to 4 classes.\n",
            "Using 511 files for training.\n",
            "Found 567 files belonging to 4 classes.\n",
            "Using 56 files for validation.\n"
          ]
        }
      ],
      "source": [
        "DIM = 227\n",
        "img_size = (DIM, DIM)\n",
        "image_height = DIM\n",
        "image_width = DIM\n",
        "\n",
        "IMG_FOLDER_PATH = BASE_DIR + \"/data\"# Add training set here\n",
        "# IMG_VAL_PATH = \"\"# Add validation set here\n",
        "# IMG_TEST_PATH = \"\"# Add test set here\n",
        "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
        "data_iter = tf.keras.utils.image_dataset_from_directory(IMG_FOLDER_PATH,\n",
        "                                                labels='inferred',\n",
        "                                                label_mode='categorical' ,\n",
        "                                                class_names=['2s', '4s', 'ch', 'cu'],\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=1,\n",
        "                                                image_size=(DIM, DIM),\n",
        "                                                shuffle=True,\n",
        "                                                seed=1,\n",
        "                                                validation_split=0.1,\n",
        "                                                subset=\"training\",\n",
        "                                                interpolation='bilinear',\n",
        "                                                follow_links=False,\n",
        "                                                crop_to_aspect_ratio=False\n",
        "\n",
        "                                               )\n",
        "val_data_iter = tf.keras.utils.image_dataset_from_directory(IMG_FOLDER_PATH,\n",
        "                                                labels='inferred',\n",
        "                                                label_mode='categorical' ,\n",
        "                                                class_names=['2s', '4s', 'ch', 'cu'],\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=1,\n",
        "                                                image_size=(DIM, DIM),\n",
        "                                                shuffle=True,\n",
        "                                                seed=1,\n",
        "                                                validation_split=0.1,\n",
        "                                                subset=\"validation\",\n",
        "                                                interpolation='bilinear',\n",
        "                                                follow_links=False,\n",
        "                                                crop_to_aspect_ratio=False\n",
        "\n",
        "                                               )\n",
        "# val_data_iter = data_generator.flow_from_directory(IMG_VAL_PATH,\n",
        "#                                                    target_size=img_size,\n",
        "#                                                    color_mode=\"rgb\",\n",
        "#                                                    batch_size=1,\n",
        "#                                                    shuffle=False,\n",
        "#                                                    class_mode=\"categorical\"\n",
        "#                                                    )\n",
        "\n",
        "# test_data_iter = data_generator.flow_from_directory(IMG_TEST_PATH,\n",
        "#                                                     target_size=img_size,\n",
        "#                                                     color_mode=\"rgb\",\n",
        "#                                                     batch_size=1,\n",
        "#                                                     shuffle=False,\n",
        "#                                                     class_mode=\"categorical\"\n",
        "#                                                     )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data_iter.\n",
        "top_0 = max(np.where(labels == 0)[0])\n",
        "top_1 = max(np.where(labels == 1)[0])\n",
        "top_2 = max(np.where(labels == 2)[0])\n",
        "top_3 = max(np.where(labels == 3)[0])\n",
        "\n",
        "labels[top_0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "8ulu_Skwg7NH",
        "outputId": "b44cff18-9a4e-49a2-e8d2-4d3c243d6e67"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-d01439f1202a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    labels = data_iter.\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a83hFm6-WEhU",
        "outputId": "590baa96-ada1-4616-ca16-fc87b710d13f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"alex_net_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_145 (Conv2D)         (None, 55, 55, 96)        34944     \n",
            "                                                                 \n",
            " max_pooling2d_87 (MaxPoolin  (None, 27, 27, 96)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_146 (Conv2D)         (None, 27, 27, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_88 (MaxPoolin  (None, 13, 13, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 13, 13, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_148 (Conv2D)         (None, 13, 13, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_149 (Conv2D)         (None, 13, 13, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_89 (MaxPoolin  (None, 6, 6, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_29 (Flatten)        (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 4096)              37752832  \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 4)                 16388     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,297,732\n",
            "Trainable params: 58,297,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# We will build a custom training loop to see how the process works\n",
        "# we compile it, load the weights\n",
        "model = AlexNet((DIM, DIM, 3), 4)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EvjxnsBcWEhW"
      },
      "outputs": [],
      "source": [
        "def visualize_representation(input, title=\"\"):\n",
        "    #input = np.reshape(input, (len(input), 1))\n",
        "    for i in [60, 200, 350, 550]:\n",
        "        val = input[i]\n",
        "        plt.figure()\n",
        "        plt.bar(x=[i for i in range(1, 4097)], height=val)\n",
        "        plt.title(title)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsFsxJzAWEhV",
        "outputId": "7bcc36a0-95b4-496b-ccab-4a46dd5e804d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1\n",
            "511/511 [==============================] - 12s 22ms/step - loss: 72.4405 - accuracy: 0.3659 - val_loss: 1.2470 - val_accuracy: 0.3571\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 2\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 1.2730 - accuracy: 0.5695 - val_loss: 1.0486 - val_accuracy: 0.5714\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 3\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 0.9842 - accuracy: 0.6888 - val_loss: 0.5930 - val_accuracy: 0.8214\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 4\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 1.0029 - accuracy: 0.6967 - val_loss: 1.3971 - val_accuracy: 0.6071\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 5\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 0.4342 - accuracy: 0.8669 - val_loss: 0.5527 - val_accuracy: 0.7857\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 6\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 0.9399 - accuracy: 0.7299 - val_loss: 0.1233 - val_accuracy: 0.9464\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 7\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 0.7818 - accuracy: 0.7436 - val_loss: 0.9013 - val_accuracy: 0.6964\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 8\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 0.3877 - accuracy: 0.8963 - val_loss: 0.2711 - val_accuracy: 0.9286\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 9\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 0.2865 - accuracy: 0.9159 - val_loss: 2.0639 - val_accuracy: 0.5357\n",
            "Length of Outputs: (511, 9216)\n",
            "Iteration 10\n",
            "511/511 [==============================] - 11s 21ms/step - loss: 0.6228 - accuracy: 0.7847 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Length of Outputs: (511, 9216)\n"
          ]
        }
      ],
      "source": [
        "# We will build a custom training loop to see how the process works\n",
        "# we compile it, load the weights\n",
        "model = AlexNet((DIM, DIM, 3), 4)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "EPOCHS = 5 * 2\n",
        "layers = [layer.name for layer in model.layers]\n",
        "\n",
        "iteration_representations = {}\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Iteration {epoch + 1}\")\n",
        "    hist = model.fit(data_iter, epochs=1, batch_size=32, validation_data=val_data_iter)\n",
        "\n",
        "    layer_cut = 9\n",
        "\n",
        "    model1 = AlexNet_Input_to_Kernels((DIM, DIM, 3))\n",
        "\n",
        "    for i in range(0, layer_cut):\n",
        "        model1.layers[i].set_weights(model.layers[i].get_weights())\n",
        "\n",
        "    # Now we can take the outputs from the cut model\n",
        "\n",
        "    outputs = model1.predict(data_iter)\n",
        "\n",
        "    print(f\"Length of Outputs: {outputs.shape}\")\n",
        "    \n",
        "    iteration_representations[epoch + 1] = outputs\n",
        "\n",
        "    #visualize_representation(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "failed_imgs = []\n",
        "for i, item in enumerate(data_iter):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VmhiIkFhg1t",
        "outputId": "c44b897b-2f4e-47c5-ea30-3d514c5e7551"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(32, 227, 227, 3), dtype=float32, numpy=\n",
            "array([[[[236.      , 244.      , 246.      ],\n",
            "         [235.18723 , 244.18723 , 243.18723 ],\n",
            "         [237.      , 246.      , 245.      ],\n",
            "         ...,\n",
            "         [146.64539 , 172.64539 , 197.64539 ],\n",
            "         [145.25337 , 169.25337 , 195.25337 ],\n",
            "         [141.35931 , 168.81732 , 193.08832 ]],\n",
            "\n",
            "        [[236.      , 244.      , 246.      ],\n",
            "         [235.18723 , 244.18723 , 243.18723 ],\n",
            "         [236.      , 245.      , 244.      ],\n",
            "         ...,\n",
            "         [146.64539 , 172.64539 , 197.64539 ],\n",
            "         [144.37451 , 168.37451 , 194.37451 ],\n",
            "         [141.54199 , 169.      , 193.271   ]],\n",
            "\n",
            "        [[235.      , 243.      , 245.      ],\n",
            "         [235.49232 , 244.49232 , 243.49232 ],\n",
            "         [236.      , 244.60573 , 244.78854 ],\n",
            "         ...,\n",
            "         [147.03966 , 173.03966 , 198.03966 ],\n",
            "         [146.5077  , 170.5077  , 196.5077  ],\n",
            "         [141.98357 , 169.44157 , 193.71257 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[112.46365 , 151.46365 ,  85.25223 ],\n",
            "         [ 79.449326, 118.449326,  52.237904],\n",
            "         [ 81.162605, 117.162605,  55.16261 ],\n",
            "         ...,\n",
            "         [142.53406 , 176.53406 , 116.53406 ],\n",
            "         [ 78.795   , 114.795   ,  53.795   ],\n",
            "         [ 90.251366, 126.251366,  65.251366]],\n",
            "\n",
            "        [[106.42872 , 142.42873 ,  79.155525],\n",
            "         [105.08165 , 141.08165 ,  77.80846 ],\n",
            "         [ 69.36783 , 105.36783 ,  43.36783 ],\n",
            "         ...,\n",
            "         [ 91.632324, 125.632324,  65.632324],\n",
            "         [ 82.03296 , 118.03296 ,  57.03296 ],\n",
            "         [ 82.1626  , 120.43359 ,  58.891605]],\n",
            "\n",
            "        [[126.10168 , 162.10167 , 100.10167 ],\n",
            "         [102.79344 , 138.79344 ,  76.79344 ],\n",
            "         [158.72537 , 194.72537 , 132.72537 ],\n",
            "         ...,\n",
            "         [106.19676 , 137.19676 ,  78.19676 ],\n",
            "         [107.66726 , 140.42506 ,  83.42507 ],\n",
            "         [ 77.591   , 111.22772 ,  51.525375]]],\n",
            "\n",
            "\n",
            "       [[[237.72908 , 245.72908 , 248.72908 ],\n",
            "         [240.      , 245.      , 249.      ],\n",
            "         [240.68834 , 245.68834 , 248.68834 ],\n",
            "         ...,\n",
            "         [158.07819 , 182.07819 , 206.07819 ],\n",
            "         [157.28572 , 179.28572 , 203.28572 ],\n",
            "         [155.      , 177.      , 201.      ]],\n",
            "\n",
            "        [[235.26497 , 243.26497 , 246.26497 ],\n",
            "         [238.93196 , 243.93196 , 247.93196 ],\n",
            "         [240.      , 245.      , 248.      ],\n",
            "         ...,\n",
            "         [154.36343 , 178.36343 , 202.36343 ],\n",
            "         [154.48264 , 176.48264 , 200.48264 ],\n",
            "         [154.      , 176.      , 200.      ]],\n",
            "\n",
            "        [[234.27092 , 242.27092 , 245.27092 ],\n",
            "         [238.60573 , 243.60573 , 247.60573 ],\n",
            "         [238.86018 , 243.86018 , 247.86018 ],\n",
            "         ...,\n",
            "         [155.86018 , 177.86018 , 201.86018 ],\n",
            "         [154.      , 176.      , 200.      ],\n",
            "         [154.      , 176.      , 200.      ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 84.42737 , 125.42737 ,  57.427364],\n",
            "         [139.31512 , 180.31512 , 112.31512 ],\n",
            "         [ 87.62123 , 128.62123 ,  61.409805],\n",
            "         ...,\n",
            "         [ 69.3928  , 108.3928  ,  45.392803],\n",
            "         [ 86.26357 , 122.26357 ,  60.263573],\n",
            "         [ 78.18926 , 117.18926 ,  54.189262]],\n",
            "\n",
            "        [[113.274925, 154.27492 ,  86.274925],\n",
            "         [103.795715, 144.79572 ,  76.795715],\n",
            "         [ 97.046875, 138.04688 ,  70.046875],\n",
            "         ...,\n",
            "         [125.50791 , 160.5079  ,  96.50791 ],\n",
            "         [121.5403  , 157.5403  ,  95.5403  ],\n",
            "         [111.201225, 150.20123 ,  85.201225]],\n",
            "\n",
            "        [[112.962524, 153.96252 ,  85.962524],\n",
            "         [105.63898 , 146.63898 ,  78.63898 ],\n",
            "         [118.36856 , 159.36856 ,  91.36856 ],\n",
            "         ...,\n",
            "         [ 84.74593 , 119.74593 ,  55.74593 ],\n",
            "         [ 95.36358 , 130.36357 ,  66.36358 ],\n",
            "         [129.81494 , 165.81494 , 101.81494 ]]],\n",
            "\n",
            "\n",
            "       [[[196.      , 212.      , 228.      ],\n",
            "         [195.      , 212.      , 230.      ],\n",
            "         [196.      , 212.      , 228.      ],\n",
            "         ...,\n",
            "         [162.      , 188.      , 213.      ],\n",
            "         [162.87886 , 188.87886 , 213.87886 ],\n",
            "         [162.12114 , 188.12114 , 213.12114 ]],\n",
            "\n",
            "        [[195.63657 , 211.63657 , 227.63657 ],\n",
            "         [196.      , 212.      , 228.      ],\n",
            "         [195.      , 212.      , 230.      ],\n",
            "         ...,\n",
            "         [161.36343 , 187.36343 , 212.36343 ],\n",
            "         [162.      , 188.      , 213.      ],\n",
            "         [160.8275  , 186.8275  , 211.8275  ]],\n",
            "\n",
            "        [[198.      , 214.      , 230.      ],\n",
            "         [198.      , 214.      , 230.      ],\n",
            "         [196.39427 , 212.39427 , 228.39427 ],\n",
            "         ...,\n",
            "         [162.      , 188.      , 213.      ],\n",
            "         [161.67955 , 187.67955 , 212.67955 ],\n",
            "         [160.60573 , 186.60573 , 211.60573 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 83.257744, 121.65203 ,  59.863457],\n",
            "         [ 94.05619 , 132.45047 ,  70.6619  ],\n",
            "         [126.448425, 165.44843 , 100.448425],\n",
            "         ...,\n",
            "         [ 73.98933 , 111.98933 ,  50.989326],\n",
            "         [ 71.97102 , 105.97102 ,  45.971027],\n",
            "         [101.23811 , 137.73055 ,  76.29541 ]],\n",
            "\n",
            "        [[ 58.815575,  96.815575,  37.815575],\n",
            "         [ 78.13023 , 116.13023 ,  55.130234],\n",
            "         [123.89434 , 162.89435 ,  96.34585 ],\n",
            "         ...,\n",
            "         [ 83.811485, 122.53829 ,  61.17489 ],\n",
            "         [ 80.812744, 116.812744,  54.812744],\n",
            "         [ 83.9685  , 124.9685  ,  58.968494]],\n",
            "\n",
            "        [[ 80.65377 , 118.65377 ,  59.65377 ],\n",
            "         [ 57.044167,  95.04417 ,  34.044167],\n",
            "         [ 97.84932 , 136.8493  ,  70.09151 ],\n",
            "         ...,\n",
            "         [ 82.91338 , 120.91338 ,  59.913383],\n",
            "         [ 67.97839 , 101.97839 ,  40.978397],\n",
            "         [ 92.89726 , 131.53398 ,  66.83163 ]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[195.      , 204.      , 213.      ],\n",
            "         [195.      , 204.      , 213.      ],\n",
            "         [194.92181 , 203.92181 , 212.92181 ],\n",
            "         ...,\n",
            "         [215.35461 , 226.35461 , 230.35461 ],\n",
            "         [ 29.298613,  36.29861 ,  42.29861 ],\n",
            "         [ 39.458008,  46.270996,  44.      ]],\n",
            "\n",
            "        [[194.      , 203.      , 212.      ],\n",
            "         [195.      , 204.      , 213.      ],\n",
            "         [193.58919 , 202.58919 , 211.58919 ],\n",
            "         ...,\n",
            "         [215.5397  , 226.5397  , 232.5397  ],\n",
            "         [ 33.712273,  40.712273,  46.712273],\n",
            "         [ 37.09244 ,  43.90543 ,  41.634434]],\n",
            "\n",
            "        [[194.16411 , 203.16411 , 210.16411 ],\n",
            "         [193.67955 , 202.67955 , 209.67955 ],\n",
            "         [194.78519 , 203.78519 , 212.78519 ],\n",
            "         ...,\n",
            "         [215.64539 , 226.64539 , 232.64539 ],\n",
            "         [ 33.19139 ,  40.19139 ,  46.19139 ],\n",
            "         [ 33.310287,  40.123276,  37.85228 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 99.696   , 137.696   ,  78.696   ],\n",
            "         [102.36666 , 138.10126 ,  79.894196],\n",
            "         [ 79.33678 , 114.670555,  57.842323],\n",
            "         ...,\n",
            "         [ 97.85344 , 132.85344 ,  78.85344 ],\n",
            "         [109.078224, 148.07823 ,  93.078224],\n",
            "         [101.018715, 140.01872 ,  85.018715]],\n",
            "\n",
            "        [[106.10072 , 141.103   ,  81.27917 ],\n",
            "         [108.669815, 140.01793 ,  85.56856 ],\n",
            "         [ 92.51861 , 112.974785,  62.064995],\n",
            "         ...,\n",
            "         [102.065025, 137.06502 ,  83.065025],\n",
            "         [109.51739 , 146.5174  ,  92.51739 ],\n",
            "         [103.18869 , 140.18869 ,  86.18869 ]],\n",
            "\n",
            "        [[115.484375, 125.75323 ,  75.812775],\n",
            "         [131.40863 , 106.78869 ,  71.05425 ],\n",
            "         [143.22429 ,  99.31168 ,  70.24219 ],\n",
            "         ...,\n",
            "         [ 88.56723 , 123.56723 ,  69.56723 ],\n",
            "         [ 92.122955, 128.88077 ,  74.88077 ],\n",
            "         [ 99.79063 , 134.79063 ,  80.79063 ]]],\n",
            "\n",
            "\n",
            "       [[[181.      , 198.      , 216.      ],\n",
            "         [181.      , 198.      , 216.      ],\n",
            "         [179.64537 , 196.64537 , 214.64537 ],\n",
            "         ...,\n",
            "         [161.      , 188.      , 217.      ],\n",
            "         [161.      , 188.      , 217.      ],\n",
            "         [162.      , 189.      , 218.      ]],\n",
            "\n",
            "        [[179.      , 196.      , 214.      ],\n",
            "         [180.      , 197.      , 215.      ],\n",
            "         [180.      , 197.      , 215.      ],\n",
            "         ...,\n",
            "         [160.      , 187.      , 216.      ],\n",
            "         [161.      , 188.      , 217.      ],\n",
            "         [161.      , 188.      , 217.      ]],\n",
            "\n",
            "        [[178.44162 , 195.44162 , 213.44162 ],\n",
            "         [178.60573 , 195.60573 , 213.60573 ],\n",
            "         [178.82054 , 195.82054 , 211.82054 ],\n",
            "         ...,\n",
            "         [159.      , 186.      , 215.      ],\n",
            "         [161.      , 188.      , 217.      ],\n",
            "         [160.      , 187.      , 216.      ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[115.56615 , 154.56615 ,  91.56615 ],\n",
            "         [ 93.47974 , 132.47974 ,  69.47974 ],\n",
            "         [117.23654 , 156.23654 ,  93.23654 ],\n",
            "         ...,\n",
            "         [ 76.889206, 105.31877 ,  47.175583],\n",
            "         [100.77834 , 135.07898 ,  73.87195 ],\n",
            "         [100.3615  , 135.15009 ,  73.75579 ]],\n",
            "\n",
            "        [[129.23497 , 168.50589 , 105.50588 ],\n",
            "         [ 80.89618 , 119.89618 ,  56.89618 ],\n",
            "         [119.89752 , 158.89752 ,  95.89752 ],\n",
            "         ...,\n",
            "         [147.00871 , 114.59513 ,  77.06632 ],\n",
            "         [130.56775 , 130.46472 ,  80.8324  ],\n",
            "         [ 81.77997 ,  99.342896,  41.433105]],\n",
            "\n",
            "        [[ 84.58157 , 120.339386,  58.46048 ],\n",
            "         [ 81.32614 , 121.32614 ,  58.32614 ],\n",
            "         [100.11689 , 139.11688 ,  76.11689 ],\n",
            "         ...,\n",
            "         [177.75896 ,  82.615814,  66.304146],\n",
            "         [169.98892 ,  91.10922 ,  69.3949  ],\n",
            "         [143.44737 , 103.95068 ,  67.77197 ]]],\n",
            "\n",
            "\n",
            "       [[[186.7619  , 194.7619  , 207.7619  ],\n",
            "         [190.12114 , 198.12114 , 211.12114 ],\n",
            "         [191.64537 , 199.64537 , 212.64537 ],\n",
            "         ...,\n",
            "         [217.35461 , 230.35461 , 236.35461 ],\n",
            "         [213.91989 , 228.91989 , 233.91989 ],\n",
            "         [ 72.45302 ,  82.911026,  87.724014]],\n",
            "\n",
            "        [[185.26497 , 195.26497 , 207.26497 ],\n",
            "         [186.36343 , 196.36343 , 208.36343 ],\n",
            "         [188.77426 , 198.77426 , 210.77426 ],\n",
            "         ...,\n",
            "         [216.35461 , 229.35461 , 235.35461 ],\n",
            "         [213.91513 , 227.91513 , 230.91513 ],\n",
            "         [ 53.422356,  63.880363,  69.60937 ]],\n",
            "\n",
            "        [[180.2588  , 191.04735 , 203.04735 ],\n",
            "         [182.21146 , 193.      , 205.      ],\n",
            "         [183.81718 , 194.60573 , 206.60573 ],\n",
            "         ...,\n",
            "         [216.89984 , 229.89984 , 235.89984 ],\n",
            "         [210.41403 , 223.23122 , 226.62549 ],\n",
            "         [ 50.59887 ,  61.056877,  66.78588 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[179.11777 ,  82.11777 ,  75.11777 ],\n",
            "         [208.8875  , 112.88749 , 100.88749 ],\n",
            "         [177.90822 ,  83.90822 ,  74.69679 ],\n",
            "         ...,\n",
            "         [107.40005 , 130.40004 ,  84.40005 ],\n",
            "         [ 90.80428 , 111.80428 ,  68.80428 ],\n",
            "         [ 65.59962 ,  86.59962 ,  43.599617]],\n",
            "\n",
            "        [[201.48886 , 104.48886 ,  96.030716],\n",
            "         [193.738   ,  97.73801 ,  85.73801 ],\n",
            "         [186.28963 ,  89.28963 ,  80.28963 ],\n",
            "         ...,\n",
            "         [102.37021 , 123.28    ,  77.6434  ],\n",
            "         [114.65198 , 136.65198 ,  90.65198 ],\n",
            "         [104.09241 , 132.45581 ,  84.45581 ]],\n",
            "\n",
            "        [[170.27551 ,  73.27551 ,  64.81736 ],\n",
            "         [200.6049  , 104.6049  ,  92.6049  ],\n",
            "         [185.31169 ,  88.31168 ,  79.31168 ],\n",
            "         ...,\n",
            "         [116.29736 , 138.29736 ,  92.29736 ],\n",
            "         [118.13046 , 140.13046 ,  94.13046 ],\n",
            "         [118.82129 , 147.82129 ,  99.82129 ]]]], dtype=float32)>, <tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
            "array([[0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0.]], dtype=float32)>)\n",
            "(<tf.Tensor: shape=(24, 227, 227, 3), dtype=float32, numpy=\n",
            "array([[[[255.      , 255.      , 255.      ],\n",
            "         [255.      , 255.      , 255.      ],\n",
            "         [255.      , 255.      , 255.      ],\n",
            "         ...,\n",
            "         [182.      , 211.      , 229.      ],\n",
            "         [179.      , 210.      , 230.      ],\n",
            "         [176.      , 207.54199 , 227.271   ]],\n",
            "\n",
            "        [[255.      , 255.      , 255.      ],\n",
            "         [255.      , 255.      , 255.      ],\n",
            "         [255.      , 255.      , 255.      ],\n",
            "         ...,\n",
            "         [182.      , 211.      , 229.      ],\n",
            "         [178.      , 209.      , 229.      ],\n",
            "         [176.      , 207.54199 , 227.271   ]],\n",
            "\n",
            "        [[255.      , 255.      , 255.      ],\n",
            "         [255.      , 255.      , 255.      ],\n",
            "         [255.      , 255.      , 255.      ],\n",
            "         ...,\n",
            "         [182.      , 211.      , 229.      ],\n",
            "         [178.11342 , 209.11342 , 229.11342 ],\n",
            "         [175.62216 , 207.16415 , 226.89316 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 79.77404 , 120.77404 ,  60.774044],\n",
            "         [ 84.23472 , 125.23472 ,  65.23472 ],\n",
            "         [117.48433 , 159.48433 ,  96.48433 ],\n",
            "         ...,\n",
            "         [205.56604 ,  94.56604 ,  85.56604 ],\n",
            "         [225.57619 , 118.97048 , 107.78762 ],\n",
            "         [202.26537 ,  98.265366,  86.47679 ]],\n",
            "\n",
            "        [[110.2769  , 151.2769  ,  91.2769  ],\n",
            "         [110.24173 , 151.24173 ,  91.24173 ],\n",
            "         [126.69538 , 168.69537 , 105.69538 ],\n",
            "         ...,\n",
            "         [200.58484 ,  92.58485 ,  82.58485 ],\n",
            "         [234.34286 , 127.342865, 119.342865],\n",
            "         [191.086   ,  86.27302 ,  77.544014]],\n",
            "\n",
            "        [[101.59396 , 142.59396 ,  82.59396 ],\n",
            "         [106.40423 , 147.40424 ,  87.40423 ],\n",
            "         [105.73325 , 147.73326 ,  84.73325 ],\n",
            "         ...,\n",
            "         [194.06834 ,  86.068344,  76.068344],\n",
            "         [194.18755 ,  87.18755 ,  79.18755 ],\n",
            "         [225.83838 , 121.02539 , 112.29639 ]]],\n",
            "\n",
            "\n",
            "       [[[236.12114 , 248.12114 , 248.12114 ],\n",
            "         [239.28569 , 251.28569 , 251.28569 ],\n",
            "         [240.07819 , 252.07819 , 251.83589 ],\n",
            "         ...,\n",
            "         [165.12114 , 187.12114 , 211.12114 ],\n",
            "         [164.59314 , 186.59314 , 210.59314 ],\n",
            "         [161.7577  , 185.7577  , 209.7577  ]],\n",
            "\n",
            "        [[231.26497 , 242.99405 , 243.53589 ],\n",
            "         [234.18723 , 245.18723 , 247.18723 ],\n",
            "         [235.36343 , 245.36343 , 247.36343 ],\n",
            "         ...,\n",
            "         [166.63657 , 188.63657 , 212.63657 ],\n",
            "         [167.15393 , 192.15393 , 214.15393 ],\n",
            "         [168.27313 , 193.27313 , 215.27313 ]],\n",
            "\n",
            "        [[228.      , 239.      , 241.78854 ],\n",
            "         [231.32045 , 242.32045 , 245.109   ],\n",
            "         [231.42627 , 241.82054 , 243.82054 ],\n",
            "         ...,\n",
            "         [167.78854 , 189.78854 , 212.78854 ],\n",
            "         [173.      , 195.      , 217.21146 ],\n",
            "         [174.66527 , 196.55843 , 218.76988 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 87.00131 , 126.00131 ,  61.001312],\n",
            "         [130.43843 , 169.43843 , 104.43842 ],\n",
            "         [ 91.92839 , 130.92839 ,  65.92839 ],\n",
            "         ...,\n",
            "         [193.52397 ,  85.52398 ,  72.52398 ],\n",
            "         [226.26404 , 119.475464, 105.86975 ],\n",
            "         [221.99707 , 117.81421 , 103.208496]],\n",
            "\n",
            "        [[ 70.7544  , 109.7544  ,  44.7544  ],\n",
            "         [ 99.06059 , 138.0606  ,  73.06059 ],\n",
            "         [144.7795  , 183.7795  , 118.779495],\n",
            "         ...,\n",
            "         [189.88193 ,  81.881935,  68.881935],\n",
            "         [189.97981 ,  83.97981 ,  69.97981 ],\n",
            "         [226.84222 , 124.84222 , 110.84222 ]],\n",
            "\n",
            "        [[ 56.198147,  95.19814 ,  30.198143],\n",
            "         [ 90.064835, 129.06483 ,  64.064835],\n",
            "         [105.5217  , 144.52171 ,  79.5217  ],\n",
            "         ...,\n",
            "         [184.73274 ,  76.73275 ,  63.732746],\n",
            "         [182.43109 ,  76.43109 ,  62.43109 ],\n",
            "         [203.20123 ,  96.95905 ,  83.31833 ]]],\n",
            "\n",
            "\n",
            "       [[[220.72908 , 225.27092 , 237.27092 ],\n",
            "         [222.      , 226.      , 238.      ],\n",
            "         [220.      , 228.      , 239.      ],\n",
            "         ...,\n",
            "         [151.68834 , 173.68834 , 197.68834 ],\n",
            "         [147.      , 172.      , 194.      ],\n",
            "         [145.87886 , 169.87886 , 194.42085 ]],\n",
            "\n",
            "        [[221.27092 , 225.27092 , 237.27092 ],\n",
            "         [220.51738 , 226.51738 , 238.51738 ],\n",
            "         [222.      , 228.      , 240.      ],\n",
            "         ...,\n",
            "         [152.      , 174.      , 198.      ],\n",
            "         [147.      , 172.      , 194.      ],\n",
            "         [146.      , 170.      , 194.54199 ]],\n",
            "\n",
            "        [[220.54185 , 226.      , 238.      ],\n",
            "         [220.60573 , 227.39427 , 239.      ],\n",
            "         [222.      , 228.      , 240.      ],\n",
            "         ...,\n",
            "         [151.      , 173.      , 197.      ],\n",
            "         [147.07384 , 172.07384 , 194.07384 ],\n",
            "         [145.      , 169.      , 193.54199 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 95.33475 , 134.33475 ,  71.33474 ],\n",
            "         [ 88.164215, 127.164215,  64.164215],\n",
            "         [ 90.37307 , 129.37306 ,  66.37307 ],\n",
            "         ...,\n",
            "         [ 63.26118 ,  99.261185,  38.26118 ],\n",
            "         [105.738335, 140.5269  ,  80.13262 ],\n",
            "         [113.03769 , 147.82626 ,  87.43198 ]],\n",
            "\n",
            "        [[115.55373 , 154.55373 ,  91.55373 ],\n",
            "         [ 85.335945, 124.335945,  61.335945],\n",
            "         [123.70771 , 162.7077  ,  99.70771 ],\n",
            "         ...,\n",
            "         [ 69.072525, 105.072525,  44.072525],\n",
            "         [ 91.916   , 127.67758 ,  66.79679 ],\n",
            "         [ 61.47716 ,  97.13213 ,  36.304646]],\n",
            "\n",
            "        [[ 68.16119 , 107.16119 ,  44.16119 ],\n",
            "         [ 42.249294,  81.2493  ,  18.249296],\n",
            "         [ 97.29729 , 136.29729 ,  73.29729 ],\n",
            "         ...,\n",
            "         [ 71.884926, 107.884926,  46.88493 ],\n",
            "         [113.01629 , 149.0163  ,  88.01629 ],\n",
            "         [110.078224, 146.07823 ,  85.078224]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[227.19318 , 232.27092 , 242.91168 ],\n",
            "         [227.      , 234.      , 244.      ],\n",
            "         [228.31166 , 235.31166 , 245.31166 ],\n",
            "         ...,\n",
            "         [170.      , 198.      , 222.      ],\n",
            "         [170.46092 , 200.46092 , 224.46092 ],\n",
            "         [172.      , 200.      , 224.      ]],\n",
            "\n",
            "        [[226.90154 , 233.90154 , 243.90154 ],\n",
            "         [226.63657 , 235.63657 , 244.63657 ],\n",
            "         [227.58919 , 234.58919 , 244.58919 ],\n",
            "         ...,\n",
            "         [170.36343 , 198.36343 , 222.36343 ],\n",
            "         [169.62549 , 199.62549 , 223.62549 ],\n",
            "         [172.271   , 200.271   , 224.271   ]],\n",
            "\n",
            "        [[224.94054 , 232.87665 , 243.      ],\n",
            "         [225.78854 , 233.60573 , 243.78854 ],\n",
            "         [227.64537 , 234.64537 , 243.85683 ],\n",
            "         ...,\n",
            "         [170.25446 , 198.25446 , 222.25446 ],\n",
            "         [168.32045 , 198.32045 , 222.32045 ],\n",
            "         [171.      , 199.      , 223.      ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 80.7617  , 116.7617  ,  46.18677 ],\n",
            "         [ 98.89639 , 134.8964  ,  64.89639 ],\n",
            "         [133.69237 , 170.69237 , 100.692375],\n",
            "         ...,\n",
            "         [111.73642 , 146.73642 ,  78.73642 ],\n",
            "         [ 76.36565 , 110.182785,  44.57707 ],\n",
            "         [153.33472 , 186.1477  , 122.87672 ]],\n",
            "\n",
            "        [[ 90.12282 , 125.12282 ,  57.122818],\n",
            "         [104.72833 , 139.72833 ,  71.72833 ],\n",
            "         [103.292885, 139.29288 ,  69.292885],\n",
            "         ...,\n",
            "         [147.40895 , 184.40895 , 115.40894 ],\n",
            "         [ 93.55168 , 130.55168 ,  61.551685],\n",
            "         [ 94.061646, 129.06165 ,  65.061646]],\n",
            "\n",
            "        [[ 69.27636 , 104.27636 ,  36.276363],\n",
            "         [134.86848 , 169.86848 , 101.868484],\n",
            "         [ 65.6932  , 101.6932  ,  31.693195],\n",
            "         ...,\n",
            "         [111.31429 , 151.31429 ,  81.31429 ],\n",
            "         [115.21902 , 155.21901 ,  85.09792 ],\n",
            "         [135.09084 , 172.09084 , 104.84865 ]]],\n",
            "\n",
            "\n",
            "       [[[203.87886 , 211.87886 , 222.87886 ],\n",
            "         [205.71431 , 213.71431 , 224.71431 ],\n",
            "         [205.64537 , 213.64537 , 224.64537 ],\n",
            "         ...,\n",
            "         [223.      , 232.      , 239.      ],\n",
            "         [222.      , 231.      , 238.      ],\n",
            "         [222.      , 231.      , 238.      ]],\n",
            "\n",
            "        [[205.63657 , 213.63657 , 224.63657 ],\n",
            "         [205.      , 213.      , 224.      ],\n",
            "         [207.      , 215.      , 226.      ],\n",
            "         ...,\n",
            "         [222.      , 231.      , 238.      ],\n",
            "         [221.63657 , 230.63657 , 237.63657 ],\n",
            "         [221.      , 230.      , 237.      ]],\n",
            "\n",
            "        [[206.10681 , 214.10681 , 225.10681 ],\n",
            "         [205.      , 213.      , 224.      ],\n",
            "         [206.78519 , 214.78519 , 225.78519 ],\n",
            "         ...,\n",
            "         [221.      , 230.      , 237.      ],\n",
            "         [220.4923  , 229.4923  , 236.4923  ],\n",
            "         [220.60573 , 229.60573 , 236.60573 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[190.02971 , 100.0297  ,  91.0297  ],\n",
            "         [176.83698 ,  82.836975,  74.0484  ],\n",
            "         [196.82089 , 101.00376 ,  91.609474],\n",
            "         ...,\n",
            "         [ 92.63762 , 127.63762 ,  71.63762 ],\n",
            "         [102.523766, 137.52377 ,  81.523766],\n",
            "         [111.25887 , 149.52986 ,  92.52987 ]],\n",
            "\n",
            "        [[179.98207 ,  86.15454 ,  76.69639 ],\n",
            "         [171.3233  ,  74.3233  ,  65.3233  ],\n",
            "         [181.3126  ,  83.31261 ,  74.31261 ],\n",
            "         ...,\n",
            "         [ 91.96545 , 126.96545 ,  70.96545 ],\n",
            "         [ 99.15364 , 134.15364 ,  78.15364 ],\n",
            "         [ 81.29764 , 119.29764 ,  62.29764 ]],\n",
            "\n",
            "        [[183.1346  ,  86.94737 ,  77.676445],\n",
            "         [172.17346 ,  74.931274,  66.294556],\n",
            "         [163.86252 ,  65.86252 ,  56.862514],\n",
            "         ...,\n",
            "         [ 81.08904 , 116.08904 ,  60.089043],\n",
            "         [ 95.50332 , 130.50333 ,  74.50332 ],\n",
            "         [ 74.32705 , 112.32705 ,  55.32705 ]]],\n",
            "\n",
            "\n",
            "       [[[193.      , 203.      , 213.      ],\n",
            "         [193.      , 203.      , 213.      ],\n",
            "         [193.      , 203.      , 213.      ],\n",
            "         ...,\n",
            "         [217.      , 230.      , 238.      ],\n",
            "         [215.18726 , 230.18726 , 235.42955 ],\n",
            "         [184.42603 , 190.6191  , 198.1654  ]],\n",
            "\n",
            "        [[193.      , 203.      , 213.      ],\n",
            "         [193.      , 203.      , 213.      ],\n",
            "         [193.      , 203.      , 213.      ],\n",
            "         ...,\n",
            "         [217.      , 230.      , 238.      ],\n",
            "         [215.37451 , 228.37451 , 234.37451 ],\n",
            "         [144.64491 , 154.37392 , 163.37392 ]],\n",
            "\n",
            "        [[193.10681 , 203.10681 , 213.10681 ],\n",
            "         [193.      , 203.      , 213.      ],\n",
            "         [193.      , 203.      , 213.      ],\n",
            "         ...,\n",
            "         [215.      , 228.      , 236.      ],\n",
            "         [216.62549 , 229.62549 , 235.62549 ],\n",
            "         [180.67342 , 193.67342 , 199.67342 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 90.00452 , 121.18738 ,  69.12129 ],\n",
            "         [109.18699 , 121.3357  ,  78.41389 ],\n",
            "         [107.578125, 100.73242 ,  64.15527 ],\n",
            "         ...,\n",
            "         [100.00779 , 122.796364,  75.40208 ],\n",
            "         [120.36257 , 148.75685 , 100.75686 ],\n",
            "         [100.05976 , 130.24261 ,  81.848335]],\n",
            "\n",
            "        [[118.55116 , 140.49962 ,  93.392914],\n",
            "         [141.37189 , 126.04698 ,  92.943085],\n",
            "         [159.96133 , 105.038666,  87.6366  ],\n",
            "         ...,\n",
            "         [117.98195 , 129.75092 ,  87.35764 ],\n",
            "         [105.66303 , 130.57281 ,  85.936226],\n",
            "         [110.22497 , 137.22498 ,  92.22497 ]],\n",
            "\n",
            "        [[144.97325 , 115.75773 ,  85.93838 ],\n",
            "         [169.29886 , 100.82528 ,  85.66143 ],\n",
            "         [172.90851 ,  97.56722 ,  87.      ],\n",
            "         ...,\n",
            "         [143.12015 ,  94.66326 ,  74.841606],\n",
            "         [102.77378 ,  97.309425,  62.85996 ],\n",
            "         [108.662796, 131.42061 ,  87.5417  ]]]], dtype=float32)>, <tf.Tensor: shape=(24, 4), dtype=float32, numpy=\n",
            "array([[0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 1., 0., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 1., 0., 0.],\n",
            "       [1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [1., 0., 0., 0.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1.],\n",
            "       [0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0.]], dtype=float32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kH5zTokcNOtc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "train_model_alexnet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}